# -*- coding: utf-8 -*-
"""funding_analysis.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Jend-jajWXap9PU8zVeho5lK4oV4LJZD

# Loading the File
"""

# Import all requirements
import pandas as pd
import matplotlib.pyplot as plt
import plotly.graph_objs as go
import seaborn as sns
import plotly.express as px
import numpy as np
from plotly.subplots import make_subplots

# Read the Excel file into a dictionary of DataFrames, with keys as sheet names
file_path = '/content/funding_list_original.xls'
excel_data = pd.read_excel(file_path, sheet_name=None)

# Get the sheet names
with pd.ExcelFile(file_path) as xls:
    sheet_names = xls.sheet_names
    sheet_count = len(sheet_names)

# Print the sheet names
print(f'Number of sheets in originally collected data: {sheet_count}\n')
print("Sheet Names:")
for name in sheet_names:
    print(name)

# Read the Excel file into a dictionary of DataFrames, with keys as sheet names
file_path = '/content/funding_list.xlsx'
excel_data = pd.read_excel(file_path, sheet_name=None)

# Get the sheet names
with pd.ExcelFile(file_path) as xls:
    sheet_names = xls.sheet_names
    sheet_count = len(sheet_names)

# Print the sheet names
print(f'Number of sheets in compiled excel: {sheet_count}\n')
print("Sheet Names:")
for name in sheet_names:
    print(name)

"""### File Description


* The version right after data collection consisted of the format as below

*   The file has 16 sheets
      * 13 sheets contain 100 rows
      * 1 sheet contains 78 rows
      * 1 sheet contains 84 rows
      * 1 sheet contains 62 rows
* Each of these sheets specify a certain type of data
  * 12 sheets are the startups categorized by the type of the startup such as SAAS, EV and so on
  * 1 sheet contains only february data of startups
*  Total the file contains 1524 comapnies and their funding data
    * mostly from the later period of 2023 to Feb 2024, i.e., most latest data
* This data is from over 10 countries

I combined all the data from the multiple pages in one page

However, I have kept the data of the recntly funded startups in Februrary 2024 separate since they have two useful columns which were not available for others, namely 'Founding Year' and 'City' which we can use later to analyse the Februrary specific list separetly.


So now, our file conatains 2 pages
* page 'all_funded' contains list of all startups (total 1524) separated by 'type' of the startup.
* page 'february_2024_funded' contains the list of startups funded in 2024 (which is also present in the all_funded page); however this page has some useful information and is kept this way for easier analysis later on of the same

We will have to further clean this data before any analysis or visualizations

# Data Cleaning
"""

# Rename the DataFrames using sheet names
main_data = {name: excel_data[name] for name in sheet_names}

# Print the renamed DataFrames
for name, df in main_data.items():
    print(f"DataFrame for sheet '{name}':")
    print(df)
    print("\n")

#  storing accordinly in two different dataframes
# feb data
feb_data = main_data['february_2024_funded']
feb_data.head()

# all data
main_df = main_data['all_funded']
main_df.head()

df = pd.DataFrame(main_df.head())

# Create a table using Plotly
fig = go.Figure(data=[go.Table(
    header=dict(values=list(df.columns),
                fill_color='lightblue',
                align='left'),
    cells=dict(values=[df[col] for col in df.columns],
               fill_color='white',
               align='left'))
])

# Update layout for better visibility
fig.update_layout(
    margin=dict(l=0, r=0, t=0, b=0),
    height=300,  # Adjust height based on number of rows
)

null_items = pd.DataFrame(main_df.isnull().sum())
null_items

# filling numerical missing values with measures of central tendencies
# Impute missing values for numerical columns
# Step 1: Convert 'Funding Amount' to float
main_df['Funding Amount (USD)'] = main_df['Funding Amount (USD)'].str.replace('[\$,]', '', regex=True).astype(float)

# Step 2: Group by 'Funding Type' and calculate median for each group
# we take the median for the respective type of funding and not the entire data
# as different levels of funding will have different amounts of funding
medians = main_df.groupby('Funding Type')['Funding Amount (USD)'].median()

# Step 3: Fill missing values in each group based on its respective median
for funding_type, median_value in medians.items():
    mask = (main_df['Funding Type'] == funding_type) & (main_df['Funding Amount (USD)'].isna())
    main_df.loc[mask, 'Funding Amount (USD)'] = median_value

# Display the DataFrame after handling missing values
main_df.head(10)

# dropping Industry null values as such rows are only 4
main_df['Industry'].fillna('Unknown', inplace=True)

# filling Country and Type null values with Unknown
main_df['Country'].fillna('Unknown', inplace=True)
main_df['Type'].fillna('Unknown', inplace=True)

main_df.isnull().sum()

"""for the sake of this code I am filling with Country and Type values with unknown.
The ideal path I would've followed would have been as follows


*   For Country: manually or updating the database via code by searching the name of the startup and looking up their profile
*   For Type: using summarization techniques, or training a model that searches the similarity between Name and Type of other rows and accordingly fills the null values- for updation via code- or doing the same manually.


"""

# Find duplicate values in the "Name" column
duplicate_names = set(main_df['Name'][main_df['Name'].duplicated(keep=False)].tolist())

print(f"There are total {len(duplicate_names)} duplicates ")
# Display the list of duplicate or non-unique values
print("Names with duplicate or non-unique values:")
print(duplicate_names)

# let's see what exactly is repeating
repeating_rows = main_df[main_df['Name'].isin(duplicate_names)]
repeating_rows

# Set display options to show more rows and columns
pd.set_option('display.max_rows', None)  # To show all rows
pd.set_option('display.max_columns', None)  # To show all columns

# Now, when you print the DataFrame, it will display all rows and columns
print(repeating_rows['Name'].value_counts())

"""Now, there are following reasons why the names are repeating upon inspection


1.   The startup got different series of funding (like Series A and Series B) and both the data for the same startup is in this database
2. The value repeats in two different types, i.e., the startup is also an Indian company that recently got funding while it is also a SAAS company so the data is in both for the same type, amount and so on with only the Type column different for the specific
3. There are also some mistakes or inconsistencies in the data
    * While checking for Bluedot.co, first it was listed as Personal Finance Type startup and then as an EV startup. I am not sure if this issue is from the side of the person aggregating the data or if the transition was factual.
    * Stuff like this is difficult to crosscheck without thorough research with the direct parties invovled both - the primary data collection/aggregator as well as the startup in question
    * LB Pharma also had a similar issue
    * However, there are also some startups which do fall under two different categories as well correctly
    * Thus, it can be safe to assume, that these startups fall under the different categories and hence occur this way
4. Startups such as Bandlab had 2 same series of funding (namely Series B) which I checked is a real thing!

So, the real question- How do you solve this?

We will take two approaches


*   We will check for every row the combination of "Name", "Funding Amount", "Funding Type", "Funding Date", and "Type" for one row and if it matches with any other combination of another row in the dataset.
    * If all these rows match that means that is is a repeat bogus value and it is safe to just remove these from the main dataframe
    * If they don't match
"""

# Store the 'Name' elements in a list
name_list = main_df['Name'].tolist()

# Create a new DataFrame with the specified columns
subset_df = main_df[['Name', 'Funding Amount (USD)', 'Funding Type', 'Funding Date', 'Type']]

# Check for duplicate combinations
duplicate_combinations = subset_df[subset_df.duplicated()]

# Print the rows with duplicate combinations
if not duplicate_combinations.empty:
    print("Rows with duplicate combinations:")
    print(duplicate_combinations)
    # Store the "Name" elements in a list
    name_list += duplicate_combinations['Name'].tolist()
else:
    print("No rows with duplicate combinations found.")

# Remove duplicates from the name_list
name_list = list(set(name_list))

# Remove one of the rows with duplicate combinations, keeping the first occurrence
main_df = main_df.drop_duplicates(subset=['Name', 'Funding Amount (USD)', 'Funding Type', 'Funding Date', 'Type'], keep='first')

# Print the updated DataFrame
main_df.head()

# Store the 'Name' elements in a list
name_list = main_df['Name'].tolist()

# Create a new DataFrame with the specified columns
subset_df = main_df[['Name', 'Funding Amount (USD)', 'Funding Type', 'Funding Date', 'Type']]

# Check for duplicate combinations with different 'Type' values
duplicate_combinations = subset_df[subset_df.duplicated(subset=['Name', 'Funding Amount (USD)', 'Funding Type', 'Funding Date'], keep=False)]

# Print the rows with duplicate combinations
if not duplicate_combinations.empty:
    print("Rows with duplicate combinations with different 'Type' values:")
    print(duplicate_combinations)
    # Store the "Name" elements in a list
    name_list += duplicate_combinations['Name'].tolist()
else:
    print("No rows with duplicate combinations with different 'Type' values found.")

# Remove duplicates from the name_list
name_list = list(set(name_list))

# Group by the specified columns and aggregate the 'Type' values
combined_types_df = main_df.groupby(['Name', 'Funding Amount (USD)', 'Funding Type', 'Funding Date']).agg({'Type': ', '.join}).reset_index()

# Update the 'Type' column in the main DataFrame
main_df['Type'] = main_df.apply(lambda row: combined_types_df.loc[(combined_types_df['Name'] == row['Name']) &
                                                                  (combined_types_df['Funding Amount (USD)'] == row['Funding Amount (USD)']) &
                                                                  (combined_types_df['Funding Type'] == row['Funding Type']) &
                                                                  (combined_types_df['Funding Date'] == row['Funding Date']),
                                                                  'Type'].iloc[0], axis=1)

# Drop duplicates from the main DataFrame, keeping only the first occurrence
main_df = main_df.drop_duplicates(subset=['Name', 'Funding Amount (USD)', 'Funding Type', 'Funding Date'], keep='first')

# Print the updated DataFrame
main_df

"""So ideally if the a 'real' duplicate here will be one with the same combination of 'Name', 'Website', 'Funding Amount (USD)', 'Funding Type', 'Funding Date' and 'Type'.

      Think of it as a concept that our primary key here is not just Name but a combination of the above mentioned columns, i.e., it is a composite key
"""

# Check for duplicates based on the combination of specified columns
duplicate_combinations = main_df.duplicated(subset=['Name', 'Website', 'Funding Amount (USD)', 'Funding Type', 'Funding Date', 'Type'], keep=False)

# Filter the DataFrame to include only the duplicate rows
duplicate_rows = main_df[duplicate_combinations]

# Print the duplicate rows
print(duplicate_rows)

"""Thus, now we have a clean data with no duplicates or null values."""

main_df.shape

"""So now we hace 1442 rows reduced from the initial 1524.
Around 5.38% of data was corrupt which we have cleaned.
"""

df = pd.DataFrame(main_df.head())

# Create a table using Plotly
fig = go.Figure(data=[go.Table(
    header=dict(values=list(df.columns),
                fill_color='lightblue',
                align='left'),
    cells=dict(values=[df[col] for col in df.columns],
               fill_color='white',
               align='left'))
])

# Update layout for better visibility
fig.update_layout(
    margin=dict(l=0, r=0, t=0, b=0),
    height=300,  # Adjust height based on number of rows
)

"""# Data Pre-processing"""

# correcting types of columns
main_df['Funding Date'] = pd.to_datetime(main_df['Funding Date'])

# Print the updated data types
print(main_df.dtypes)

main_df.info()

main_df.describe().T

"""Also, we are not doing one-hot encoding since it is not required as of now and we can do with string"""

# Extract unique elements from the 'Industry' column for all rows
industries = set(main_df['Industry'].str.split(', ').sum())

# Print
print(f'{len(industries)} Industries\n{industries}')

type_counts = main_df['Funding Type'].value_counts()

# Convert Series to DataFrame
type_counts_df = pd.DataFrame({'Funding Type': type_counts.index, 'Count': type_counts.values})

# Create table using Plotly
fig = go.Figure(data=[go.Table(
    header=dict(values=["Funding Type", "Count"],
                fill_color='lightblue',
                align='left'),
    cells=dict(values=[type_counts_df["Funding Type"], type_counts_df["Count"]],
               fill_color='white',
               align='left'))
])

# Update layout for better visibility
fig.update_layout(
    margin=dict(l=0, r=0, t=0, b=0),
    height=400  # Adjust height based on number of rows
)

# Show table
fig.show()

# Trim leading and trailing whitespaces from column names
# I am doing this as only "Website" was giving an error as there might
# have been leading or trailing whitespaces in it
main_df.columns = main_df.columns.str.strip()

# Drop the 'Website' column
main_df.drop('Website', inplace=True, axis=1)

main_df.head(10)

"""# EDA"""

main_df.describe().T

"""### Most Occruing Industry



*   First we check combination wise
*   Then we check one by one


"""

# Count the occurrences of each industry
industry_counts = main_df['Industry'].str.split(',').explode().str.strip().value_counts()

# Get the top 5 most recurring industries
top_10_recurring_industries = industry_counts.head(10)

print("Top 10 most recurring individual industries:")
print(top_10_recurring_industries)

# Extract industry names and counts
industries = top_10_recurring_industries.index.tolist()
counts = top_10_recurring_industries.values.tolist()

# Create histogram
fig = go.Figure([go.Bar(x=industries, y=counts)])

# Update layout
fig.update_layout(
    title="Top 10 Most Recurring Individual Industries",
    xaxis_title="Industry",
    yaxis_title="Count"
)

# Show histogram
fig.show()

# Plot the horizontal bar chart using Seaborn
plt.figure(figsize=(10, 5))
sns.barplot(x=top_10_recurring_industries.values, y=top_10_recurring_industries.index, color='skyblue')

# Add labels and title
plt.xlabel('Frequency')
plt.ylabel('Industry')
plt.title('Top 10 Most Recurring Industries')

# Add value labels to each bar
for i, v in enumerate(top_10_recurring_industries.values):
    plt.text(v + 0.1, i, str(v), ha='left', va='center')

plt.show()

"""How many startups were funded in each country"""

# Group by 'Country' and count the number of rows
country_counts = main_df['Country'].value_counts()

# Create a bar chart
fig = px.bar(country_counts, x=country_counts.values, y=country_counts.index,
             orientation='h',
             labels={'x': 'Number of Startups', 'y': 'Country'},
             title='Number of Startups Funded in each Country')

# Show the interactive plot
fig.show()

main_df.head()

'''
Here even if 1 startup is founded in say Country A,
it can still have more than 1 industries displayed
as the same startup can fall under more than 1
industries
So this merely relects, the occurences of Industry types alone
for each country
'''
## Create a copy of the dataset
df_copy = main_df.copy()

# Split industries into individual entries and explode the resulting Series
df_copy['Industry'] = df_copy['Industry'].str.split(', ')
df_copy = df_copy.explode('Industry')

# Group by 'Country' and 'Industry', then count the occurrences of each industry for each country
industry_counts_by_country = df_copy.groupby(['Country', 'Industry']).size().reset_index(name='Count')

# Get the top 10 most recurring industries for each country
top_10_by_country = industry_counts_by_country.groupby('Country').apply(lambda x: x.nlargest(10, 'Count')).reset_index(drop=True)

# Set the aesthetic color
color = '#B5838D'

# Determine the number of countries
num_countries = len(top_10_by_country['Country'].unique())

# Calculate the figure size based on the number of countries
fig_height = num_countries * 5

# Create subplots for each country
fig = make_subplots(rows=num_countries, cols=1, subplot_titles=top_10_by_country['Country'].unique())

# Populate subplots with horizontal bar charts for each country
for i, country in enumerate(top_10_by_country['Country'].unique()):
    country_data = top_10_by_country[top_10_by_country['Country'] == country]
    fig.add_trace(go.Bar(y=country_data['Industry'], x=country_data['Count'], orientation='h', marker_color=color), row=i+1, col=1)
    fig.update_yaxes(title_text='Industry', row=i+1, col=1)
    fig.update_xaxes(title_text='Number of Startups', row=i+1, col=1)

    # Add counts on each bar
    for idx, value in enumerate(country_data['Count']):
        fig.add_annotation(text=str(value), x=value, y=country_data['Industry'].iloc[idx], showarrow=False)

    # Set subplot title
    fig.update_yaxes(title=f"Top Most recurring Industries for country {country}", row=i+1, col=1)

# Update layout
fig.update_layout(height=fig_height*100, width=800, showlegend=False)

# Show the plot
fig.show()

'''
Here even if 1 startup is founded in say Country A,
it can still have more than 1 industries displayed
as the same startup can fall under more than 1
industries
So this merely relects, the occurences of Industry types alone
for each country
'''

## Create a copy of the dataset
df_copy = main_df.copy()

# Split industries into individual entries and explode the resulting Series
df_copy['Industry'] = df_copy['Industry'].str.split(', ')
df_copy = df_copy.explode('Industry')

# Group by 'Country' and 'Industry', then count the occurrences of each industry for each country
industry_counts_by_country = df_copy.groupby(['Country', 'Industry']).size().reset_index(name='Count')

# Get the top 10 most recurring industries for each country
top_10_by_country = industry_counts_by_country.groupby('Country').apply(lambda x: x.nlargest(10, 'Count')).reset_index(drop=True)

# Set the aesthetic color
color = '#B5838D'

# Determine the number of countries
num_countries = len(top_10_by_country['Country'].unique())

# Calculate the figure size based on the number of countries
fig_height = num_countries * 5

# Create subplots for each country
fig = make_subplots(rows=num_countries, cols=1, subplot_titles=top_10_by_country['Country'].unique())

# Populate subplots with horizontal bar charts for each country
for i, country in enumerate(top_10_by_country['Country'].unique()):
    country_data = top_10_by_country[top_10_by_country['Country'] == country]
    total_count = country_data['Count'].sum()
    percentages = country_data['Count'] / total_count * 100

    fig.add_trace(go.Bar(y=country_data['Industry'], x=percentages, orientation='h', marker_color=color), row=i+1, col=1)
    fig.update_yaxes(title_text='Industry', row=i+1, col=1)
    fig.update_xaxes(title_text='Percentage of Startups', row=i+1, col=1)

    # Add percentages on each bar
    for idx, value in enumerate(percentages):
        fig.add_annotation(text=f"{value:.2f}%", x=value, y=country_data['Industry'].iloc[idx], showarrow=False)

    # Set subplot title
    fig.update_yaxes(title=f"Top Most recurring Industries for country {country}", row=i+1, col=1)

# Update layout
fig.update_layout(height=fig_height*100, width=800, showlegend=False)

# Show the plot
fig.show()

# Create a copy of the dataset
df_copy = main_df.copy()

# Split industries into individual entries and explode the resulting Series
df_copy['Industry'] = df_copy['Industry'].str.split(', ')
df_copy = df_copy.explode('Industry')

# Group by 'Country' and 'Industry', then sum the funding amount for each industry for each country
funding_amount_by_country = df_copy.groupby(['Country', 'Industry'])['Funding Amount (USD)'].sum().reset_index()

# Get the top 10 industries by funding amount for each country
top_10_by_country = funding_amount_by_country.groupby('Country').apply(lambda x: x.nlargest(10, 'Funding Amount (USD)')).reset_index(drop=True)

# Set the aesthetic color
color = '#B5838D'

# Determine the number of countries
num_countries = len(top_10_by_country['Country'].unique())

# Calculate the figure size based on the number of countries
fig_height = num_countries * 400

# Create subplots for each country
fig = make_subplots(rows=num_countries, cols=1, subplot_titles=top_10_by_country['Country'].unique())

# Populate subplots with horizontal bar charts for each country
for i, country in enumerate(top_10_by_country['Country'].unique()):
    country_data = top_10_by_country[top_10_by_country['Country'] == country]
    fig.add_trace(go.Bar(y=country_data['Industry'], x=country_data['Funding Amount (USD)'], orientation='h', marker_color=color), row=i+1, col=1)
    fig.update_yaxes(title_text='Industry', row=i+1, col=1)
    fig.update_xaxes(title_text='Funding Amount (USD)', row=i+1, col=1)

    # Add funding amount on each bar
    for idx, value in enumerate(country_data['Funding Amount (USD)']):
        fig.add_annotation(text=f"${value:,.0f}", x=value, y=country_data['Industry'].iloc[idx], showarrow=False)

# Update layout
fig.update_layout(height=fig_height, width=800, showlegend=False)

# Show the plot
fig.show()

# Calculate the total funding amount
total_funding = main_df['Funding Amount (USD)'].sum()

# Calculate the funding amount for each country
funding_by_country = main_df.groupby('Country')['Funding Amount (USD)'].sum().reset_index()

# Sort the countries by funding amount and select the top 10
top_10_countries = funding_by_country.nlargest(10, 'Funding Amount (USD)')

# Calculate the funding percentage for each top country
top_10_countries['Funding Percentage'] = top_10_countries['Funding Amount (USD)'] / total_funding * 100

# Convert funding amounts to billions for display in legend
top_10_countries['Funding Amount (Billions)'] = top_10_countries['Funding Amount (USD)'] / 1e9

# Create a pie chart
fig = px.pie(top_10_countries, values='Funding Amount (USD)', names='Country',
             title='Top 10 Countries by Funding Amount',
             hover_data={'Funding Percentage': True, 'Funding Amount (Billions)': False},
             labels={'Funding Amount (USD)': 'Funding Amount', 'Country': 'Country'},
             )

# Modify legend labels to display funding amounts in billions
for trace, country in zip(fig.data, top_10_countries['Country']):
    trace.name = f'{country} (${top_10_countries[top_10_countries["Country"] == country]["Funding Amount (Billions)"].iloc[0]:.2f}B)'

# Show the plot
fig.show()

# Create a table
table_data = top_10_countries[['Country', 'Funding Amount (USD)', 'Funding Percentage']].copy()
table_data['Funding Amount (Billions)'] = table_data['Funding Amount (USD)'] / 1e9
table_data = table_data.rename(columns={'Funding Amount (USD)': 'Funding Amount'})

fig = go.Figure(data=[go.Table(
    header=dict(values=['Country', 'Funding Amount', 'Funding Percentage'],
                fill_color='paleturquoise',
                align='left'),
    cells=dict(values=[table_data['Country'], table_data['Funding Amount'], table_data['Funding Percentage']],
               fill_color='lavender',
               align='left'))
])

# Update layout
fig.update_layout(
    title='Funding Amount by Country',
    height = 500
)

# Show the table
fig.show()

# Type of funding count

# Group the data by Funding Type and count the number of startups
overall_startup_counts = main_df.groupby('Funding Type').size().reset_index(name='Count')

# Create the histogram
fig = px.bar(overall_startup_counts, x='Funding Type', y='Count',
             labels={'Count': 'Number of Startups', 'Funding Type': 'Funding Type'},
             title='Overall Number of Startups by Funding Type',
             color_discrete_sequence=px.colors.qualitative.Dark24)

# Add text annotations to display the count on top of each bar
for i, count in enumerate(overall_startup_counts['Count']):
    fig.add_annotation(x=overall_startup_counts['Funding Type'][i], y=count,
                       text=str(count), showarrow=False)

# Update layout
fig.update_layout(xaxis_title='Funding Type', yaxis_title='Number of Startups', showlegend=False)

# Show the plot
fig.show()

# Create the line plot
fig = px.line(overall_startup_counts, x='Funding Type', y='Count',
              labels={'Count': 'Number of Startups', 'Funding Type': 'Funding Type'},
              title='Overall Number of Startups by Funding Type',
              color_discrete_sequence=px.colors.qualitative.Dark24)

# Update layout
fig.update_layout(xaxis_title='Funding Type', yaxis_title='Number of Startups', showlegend=False)

# Show the plot
fig.show()

# Create a histogram for each country
for country, data in main_df.groupby('Country'):
    # Group the data by Funding Type and count the number of startups
    startup_counts = data.groupby('Funding Type').size().reset_index(name='Count')

    # Create the histogram
    fig = px.bar(startup_counts, x='Funding Type', y='Count', color='Funding Type',
                 labels={'Count': 'Number of Startups', 'Funding Type': 'Funding Type'},
                 title=f'Number of Startups by Funding Type in {country}',
                 color_discrete_sequence=px.colors.qualitative.Dark24)

    # Update layout
    fig.update_layout(xaxis_title='Funding Type', yaxis_title='Number of Startups', showlegend=True)

    # Show the plot
    fig.show()

# Group by country and industry, then sum the funding amounts
grouped = main_df.groupby(['Country', 'Industry', 'Funding Type'])['Funding Amount (USD)'].sum().reset_index()

# Filter for the top 10 industries
top_10_industries = industry_counts.head(10).index

# Filter the grouped DataFrame for only the top 10 industries
grouped_top_10 = grouped[grouped['Industry'].isin(top_10_industries)]

# Pivot the data to create a table
pivot_table = grouped_top_10.pivot_table(index=['Country', 'Industry'], columns='Funding Type', values='Funding Amount (USD)', aggfunc='sum').fillna(0)

# Create the table
pivot_table

# Convert 'Funding Date' column to datetime
main_df['Funding Date'] = pd.to_datetime(main_df['Funding Date'])

# Group by funding date and sum the funding amounts
total_funding_over_time = main_df.groupby('Funding Date')['Funding Amount (USD)'].sum().reset_index()

# Plot the line graph
fig = px.line(total_funding_over_time, x='Funding Date', y='Funding Amount (USD)', title='Total Funding Over Time')
fig.update_xaxes(title_text='Date')
fig.update_yaxes(title_text='Total Funding (USD)')
fig.show()

# Convert 'Funding Date' column to datetime
main_df['Funding Date'] = pd.to_datetime(main_df['Funding Date'])

# Group by country and funding date, and sum the funding amounts
total_funding_by_country_over_time = main_df.groupby(['Country', 'Funding Date'])['Funding Amount (USD)'].sum().reset_index()

# Plot line graphs for each country
for country in total_funding_by_country_over_time['Country'].unique():
    # Filter data for the current country
    country_data = total_funding_by_country_over_time[total_funding_by_country_over_time['Country'] == country]

    # Plot the line graph for the current country
    fig = px.line(country_data, x='Funding Date', y='Funding Amount (USD)', title=f'Total Funding Over Time in {country}')
    fig.update_xaxes(title_text='Date')
    fig.update_yaxes(title_text='Total Funding (USD)')
    fig.show()

# Calculate the overall funding range for the graph
overall_min = main_df['Funding Amount (USD)'].min()
overall_max = main_df['Funding Amount (USD)'].max()

# Calculate the total funding amount for each country
country_funding = main_df.groupby('Country')['Funding Amount (USD)'].sum().reset_index()

# Create a choropleth map for each country
data = []
for i, row in country_funding.iterrows():
    fig = go.Choropleth(
        locations=[row['Country']],
        z=[row['Funding Amount (USD)']],  # Use total funding amount for the color scale
        locationmode='country names',
        colorscale='Viridis',
        zmin=overall_min,
        zmax=overall_max,
        colorbar_title='Funding Amount (USD)',
        hovertext=f"Country: {row['Country']}<br>Total Funding: ${row['Funding Amount (USD)']:,}",
        hoverinfo='text',
    )
    data.append(fig)

# Define the layout with adjustments for the color bar
layout = go.Layout(
    coloraxis_colorbar=dict(
        title='Funding Amount (USD)',
        title_font=dict(size=14),
        tickfont=dict(size=12),
        ticks='outside',
        tickvals=[overall_min, (overall_min + overall_max) / 2, overall_max],  # Display only the middle, first, and last values
        ticktext=[f"${overall_min:,}", f"${(overall_min + overall_max) / 2:,.0f}", f"${overall_max:,}"]
    )
)

# Create the figure
fig = go.Figure(data=data, layout=layout)

# Display the map
fig.show()

'''
As an investor, you would invest in the industry type of startup that has the
highest average funding amount.
This can be determined by calculating the average funding amount for each
individual industry and selecting the one with the highest average.
'''
# Calculate the average funding amount for each individual industry
avg_funding_by_industry = main_df.groupby('Industry')['Funding Amount (USD)'].mean().reset_index()

# Find the industry with the highest average funding amount
highest_avg_funding_industry = avg_funding_by_industry.loc[avg_funding_by_industry['Funding Amount (USD)'].idxmax()]

# Print the industry type with the highest average funding amount
print("As an investor, I would invest in the industry type of startup that has the highest average funding amount.")
print("Industry type with the highest average funding amount:", highest_avg_funding_industry['Industry'])

'''
If your startup falls under one of the top 10 occurring industries
(taken individually), you are most likely to get funding in the country where
the highest total funding amount has been received for that particular industry.
'''
# Group the DataFrame by industry and country, then calculate the total funding amount for each combination
total_funding_by_industry_country = main_df.groupby(['Industry', 'Country'])['Funding Amount (USD)'].sum().reset_index()

# Filter the DataFrame to include only the top 10 occurring industries
top_10_industries = main_df['Industry'].str.split(', ').explode().value_counts().head(10).index

# Iterate over the top 10 industries to find the country with the highest total funding amount for each industry
for industry in top_10_industries:
    industry_countries = total_funding_by_industry_country[total_funding_by_industry_country['Industry'].str.contains(industry)]
    if not industry_countries.empty:
        max_funding_index = industry_countries['Funding Amount (USD)'].idxmax()
        top_country_for_industry = industry_countries.loc[max_funding_index]
        print(f"If my startup falls under the industry '{industry}', I am most likely to get funding in {top_country_for_industry['Country']}.")

'''
To determine which industries of startups you should apply to for more
internships based on the assumption that more funding equates to more
internships, you would look for industries with higher average funding amounts.
'''
# Make a copy of the DataFrame
main_df_copy = main_df.copy()

# Split the 'Industry' column into individual industries and explode them
main_df_copy['Industry'] = main_df_copy['Industry'].str.split(', ')
main_df_copy = main_df_copy.explode('Industry')

# Calculate the average funding amount for each individual industry
avg_funding_by_industry = main_df_copy.groupby('Industry')['Funding Amount (USD)'].mean().reset_index()

# Sort the DataFrame by average funding amount in descending order
sorted_avg_funding_by_industry = avg_funding_by_industry.sort_values(by='Funding Amount (USD)', ascending=False)

# Print the top industries to apply to for more internships
print("Based on the assumption that more funding = more internships, the industries of startups I should apply to for internships are:")
print(sorted_avg_funding_by_industry['Industry'].head(5)) # Adjust the number as needed

# Sort the DataFrame by funding amount in descending order
top_10_startups = main_df.sort_values(by='Funding Amount (USD)', ascending=False).head(10)

# Create a bar plot using Plotly
fig = px.bar(top_10_startups, x='Funding Amount (USD)', y='Name', color='Industry',
             orientation='h', title='Top 10 Startups by Funding Amount')

# Add country names as text annotations on each bar
for index, row in top_10_startups.iterrows():
    fig.add_annotation(x=row['Funding Amount (USD)'], y=row['Name'], text=row['Country'],
                       showarrow=False, font=dict(color='black', size=10))

fig.update_layout(xaxis_title='Funding Amount (USD)', yaxis_title='Startup Name')
fig.show()